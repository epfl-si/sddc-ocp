- tags: always
  include_vars: "{{ item }}"
  with_items:
    - versions.yml
    - resources.yml

- tags: always
  include_vars: "{{ item }}"
  with_items:
    # The `ocp-install-config.yaml` template in the next task below
    # wants these, so as to set up ssh access to managed nodes (and
    # also, https://github.com/ansible/ansible/issues/57751 forces us
    # to do things this way):
    - ssh-public-keys.yml
    - access.yml

- name: "`openshift-install-config` Secret"
  kubernetes.core.k8s:
    definition:
      kind: Secret
      metadata:
        name: openshift-install-config
        namespace: "{{ spoke_namespace_in_hub }}"
      stringData:
        "install-config.yaml": >-
          {{ lookup("template", "ocp-install-config.yaml") }}
  vars:
    # The template explicitly expects the following variables:
    ocp_config_pull_secret: "{{ xaasible_pull_secret }}"
    ocp_config_resources: >-
      {{ resources_openshift_clusters[inventory_hostname] }}

- name: ClusterDeployment object
  register: _spoke_clusterdeployment
  kubernetes.core.k8s:
    definition:
      apiVersion: hive.openshift.io/v1
      kind: ClusterDeployment
      metadata:
        # Just like the non-namespaced ManagedCluster object creates a
        # namespace with the same name, the Hive operator assumes that
        # ClusterDeployment objects must have the same name as the
        # namespace they live in for the “import cluster” feature to
        # work.
        name: "{{ spoke_namespace_in_hub }}"
        namespace: "{{ spoke_namespace_in_hub }}"
      spec:
        baseDomain: "{{ cluster_base_domain }}"
        clusterName: "{{ cluster_name }}"
        platform:
          vsphere:
            # As seen in `oc explain ClusterDeployment.spec.platform.vsphere`
            cluster:          "{{ _vsphere_placement.cluster }}"
            datacenter:       "{{ _vsphere_placement.dc }}"
            defaultDatastore: "{{ _vsphere_placement.datastore }}"
            folder: >-
              {{ lookup("template", "vm-folder-full",
              template_vars=dict(_vm_placement=_vsphere_placement))
              | trim }}
            network: "{{ _network_name }}"

            vCenter:  "{{ vsphere_credentials.host }}"
            # The objects referenced below are created by
            # ../../roles/openshift4-hub/tasks/hub-spokes-config.yml
            credentialsSecretRef:
              name: spoke-vsphere-credentials
            certificatesSecretRef:
              name: vcenter-cert-bundle
        provisioning:
          imageSetRef:
            name: "{{ spoke_clusterimageset_name }}"
          installConfigSecretRef:
            name: openshift-install-config
        pullSecretRef:
          name: spoke-pull-secret
  vars:
    _resources: >-
      {{ resources_openshift_clusters[inventory_hostname] }}
    _vsphere_placement: >-
      {{ _resources.vsphere_placement }}
    _network_name: >-
      {{ _vsphere_placement.network.name }}

- run_once: true
  when: _spoke_clusterdeployment is changed
  pause:
    echo: false
    seconds: 1
    prompt: |
      ==========================================================================

      OpenShift installation is in progress in spoke clusters; this might take some time.

      If you are bored, feel free to watch progress at

          https://console-openshift-console.apps.{{ inventory_hub_cluster }}/multicloud/infrastructure/clusters/managed

      and click on the “Creating” hyperlinks to watch logs.

      ==========================================================================


- name: >-
    {{ "Wait for the spoke cluster(s) to come up"
    if _spoke_clusterdeployment is changed
    else "Check that the spoke cluster(s) are up"
    }}
  retries: >-
    {{ 50
    if _spoke_clusterdeployment is changed else 1 }}
  delay: 60
  register: _oc_get_clusterdeployment_installed
  until: >-
    "true" == _oc_get_clusterdeployment_installed.stdout
  changed_when: false
  shell:
    cmd: |
      oc -n {{ spoke_namespace_in_hub }} get clusterdeployment  {{ spoke_namespace_in_hub }} \
        -o jsonpath="{.spec.installed}"
